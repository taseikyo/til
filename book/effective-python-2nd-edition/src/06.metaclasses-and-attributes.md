# 6. Metaclasses and Attributes

## Item 44: Use Plain Attributes Instead of Setter and Getter Methods

```python
class OldResistor:
    def __init__(self, ohms):
    	self._ohms = ohms

    def get_ohms(self):
    	return self._ohms

    def set_ohms(self, ohms):
    	self._ohms = ohms

r0 = OldResistor(50e3)
r0.set_ohms(10e3)
```

In Python, however, you never need to implement explicit setter or getter methods. Instead, you should always start your implementations with simple public attributes.

```python
class Resistor:
    def __init__(self, ohms):
    	self.ohms = ohms
    	self.voltage = 0
    	self.current = 0

r1 = Resistor(50e3)
r1.ohms = 10e3

r1.ohms += 5e3
```

Later, if I decide I need special behavior when an attribute is set, I can migrate to the `@property` decorator and its corresponding `setter` attribute

Note that in order for this code to work properly, the names of both the `setter` and the `getter` methods must match the intended property name

```python
class VoltageResistance(Resistor):
    def __init__(self, ohms):
        super().__init__(ohms)
        self._voltage = 0

    @property
    def voltage(self):
        return self._voltage

    @voltage.setter
    def voltage(self, voltage):
        self._voltage = voltage
        self.current = self._voltage / self.ohms

r2 = VoltageResistance(1e3)
print(f'Before: {r2.current:.2f} amps')
r2.voltage = 10
print(f'After: {r2.current:.2f} amps')
```

Now, assigning the *voltage* property will run the *voltage* `setter` method, which in turn will update the *current* attribute of the object to match

Specifying a `setter` on a property also enables me to perform type checking and validation on values passed to the class

```python
class BoundedResistance(Resistor):
    def __init__(self, ohms):
        super().__init__(ohms)

    @property
    def ohms(self):
        return self._ohms

    @ohms.setter
    def ohms(self, ohms):
        if ohms <= 0:
            raise ValueError(f'ohms must be > 0; got {ohms}')
        self._ohms = ohms
```

Assigning an invalid resistance to the attribute now raises an exception

```python
r3 = BoundedResistance(1e3)
r3.ohms = 0

>>>
Traceback ...
ValueError: ohms must be > 0; got 0
```

I can even use @property to make attributes from parent classes immutable:

```python
class FixedResistance(Resistor):
    def __init__(self, ohms):
        super().__init__(ohms)

    @property
    def ohms(self):
        return self._ohms

    @ohms.setter
    def ohms(self, ohms):
        if hasattr(self, '_ohms'):
            raise AttributeError("Ohms is immutable")
        self._ohms = ohms
```

Trying to assign to the property after construction raises an exception:

```python
r4 = FixedResistance(1e3) r4.ohms = 2e3

>>>
Traceback ...
AttributeError: Ohms is immutable
```

When you use `@property` methods to implement `setters` and `getters`, be sure that the behavior you implement is not surprising

```python
class MysteriousResistor(Resistor):
    @property
    def ohms(self):
        self.voltage = self._ohms * self.current
        return self._ohms

    @ohms.setter
    def ohms(self, ohms):
        self._ohms = ohms
```

Setting other attributes in `getter` property methods leads to extremely bizarre behavior

```python
r7 = MysteriousResistor(10)
r7.current = 0.01
print(f'Before: {r7.voltage:.2f}')
r7.ohms
print(f'After: {r7.voltage:.2f}')

>>>
Before: 0.00
After: 0.10
```

The best policy is to modify only related object state in `@property.setter` methods

The biggest shortcoming of `@property` is that the methods for an attribute can only be shared by subclasses

- Define new class interfaces using simple public attributes and avoid defining setter and getter methods
- Use @property to define special behavior when attributes are accessed on your objects, if necessary
- Follow the rule of least surprise and avoid odd side effects in your @property methods
- Ensure that @property methods are fast; for slow or complex work— especially involving I/O or causing side effects—use normal methods instead

## Item 46: Use Descriptors for Reusable @property Methods

```python
class Exam:
    def __init__(self):
        self._writing_grade = 0
        self._math_grade = 0

    @staticmethod
    def _check_grade(value):
        if not (0 <= value <= 100):
            raise ValueError('Grade must be between 0 and 100')

    @property
    def writing_grade(self):
        return self._writing_grade

    @writing_grade.setter
    def writing_grade(self, value):
        self._check_grade(value)
        self._writing_grade = value

    @property
    def math_grade(self):
        return self._math_grade

    @math_grade.setter
    def math_grade(self, value):
        self._check_grade(value)
        self._math_grade = value
```

If I want to reuse this percentage validation in other classes beyond homework and exams, I’ll need to write the @property boilerplate and `_check_grade` method over and over again

The better way to do this in Python is to use a descriptor. The descriptor protocol defines how attribute access is interpreted by the language. A descriptor class can provide `__get__` and `__set__` methods that let you reuse the grade validation behavior without boilerplate

```python
class Grade:
	def __get__(self, instance, instance_type):
		...

	def __set__(self, instance, value):
		...

class Exam:
	# Class attributes
	math_grade = Grade()
	writing_grade = Grade()
	science_grade = Grade()
```

it’s important to understand what Python will do when such descriptor attributes are accessed on an Exam instance

```python
exam = Exam()
exam.writing_grade = 40
```

it is interpreted as:

`Exam.__dict__['writing_grade'].__set__(exam, 40)`

When I retrieve a property:

`exam.writing_grade`

it is interpreted as:

`Exam.__dict__['writing_grade'].__get__(exam, Exam)`


```python
class Grade:
    def __init__(self):
        self._value = 0

    def __get__(self, instance, instance_type):
        return self._value

    def __set__(self, instance, value):
        if not (0 <= value <= 100):
            raise ValueError('Grade must be between 0 and 100')
        self._value = value


class Exam:
    math_grade = Grade()
    writing_grade = Grade()
    science_grade = Grade()
```

Unfortunately, this is wrong and results in broken behavior

Accessing multiple attributes on a single Exam instance works as expected

```python
first_exam = Exam()
first_exam.writing_grade = 82
first_exam.science_grade = 99
print('Writing', first_exam.writing_grade)
print('Science', first_exam.science_grade)
>>>
Writing 82
Science 99
```

But accessing these attributes on multiple Exam instances causes
unexpected behavior

```python
second_exam = Exam()
second_exam.writing_grade = 75
print(f'Second {second_exam.writing_grade} is right')
print(f'First {first_exam.writing_grade} is wrong; should be 82')
>>>
Second 75 is right
First 75 is wrong; should be 82
```

The problem is that a single Grade instance is shared across all Exam instances for the class attribute `writing_grade`

The Grade instance for this attribute is constructed once in the program lifetime, when the Exam class is first defined, not each time an Exam instance is created

```python
class Grade:
    def __init__(self):
        self._values = {}

    def __get__(self, instance, instance_type):
        if instance is None:
            return self
        return self._values.get(instance, 0)

    def __set__(self, instance, value):
        if not (0 <= value <= 100):
            raise ValueError('Grade must be between 0 and 100')
        self._values[instance] = value
```

This implementation is simple and works well, but there’s still one gotcha: It leaks memory

The `_values` dictionary holds a reference to every instance of Exam ever passed to `__set__` over the lifetime of the program

This causes instances to never have their reference count go to zero, preventing cleanup by the garbage collector

To fix this, I can use Python’s weakref built-in module

This module provides a special class called `WeakKeyDictionary` that can take the place of the simple dictionary used for `_values`

The unique behavior of `WeakKeyDictionary` is that it removes Exam instances from its set of items when the Python runtime knows it’s holding the instance’s last remaining reference in the program

```python
from weakref import WeakKeyDictionary

class Grade:
	def __init__(self):
		self._values = WeakKeyDictionary()

	def __get__(self, instance, instance_type):
		...

	def __set__(self, instance, value):
		...
```


- Reuse the behavior and validation of `@property` methods by defining your own descriptor classes
- Use `WeakKeyDictionary` to ensure that your descriptor classes don’t cause memory leaks
- Don’t get bogged down trying to understand exactly how `__getattribute__` uses the descriptor protocol for getting and setting attributes

## Item 47: Use __getattr__, __getattribute__, and __setattr__ for Lazy Attributes

If a class defines `__getattr__`, that method is called every time an attribute can’t be found in an object’s instance dictionary

```python
class LazyRecord:
    def __init__(self):
        self.exists = 5

	def __getattr__(self, name):
	    value = f'Value for {name}'
	    setattr(self, name, value)
	    return value

data = LazyRecord()
print('Before:', data.__dict__)
print('foo: ', data.foo)
print('After: ', data.__dict__)
>>>
Before: {'exists': 5}
foo: Value for foo
After: {'exists': 5, 'foo': 'Value for foo'}
```

```python
class LoggingLazyRecord(LazyRecord):
    def __getattr__(self, name):
        print(f'* Called __getattr__({name!r}), '
              f'populating instance dictionary')
        result = super().__getattr__(name)
        print(f'* Returning {result!r}')
        return result

data = LoggingLazyRecord()
print('exists: ', data.exists)
print('First foo: ', data.foo)
print('Second foo: ', data.foo)
>>>
exists: 5
* Called __getattr__('foo'), populating instance dictionary
* Returning 'Value for foo'
First foo: Value for foo
Second foo: Value for foo
```

Python has another object hook called `__getattribute__`. This special method is called every time an attribute is accessed on an object, even in cases where it does exist in the attribute dictionary

```python
class ValidatingRecord:
    def __init__(self):
        self.exists = 5

    def __getattribute__(self, name):
        print(f'* Called __getattribute__({name!r})')
        try:
            value = super().__getattribute__(name)
            print(f'* Found {name!r}, returning {value!r}')
            return value
        except AttributeError:
            value = f'Value for {name}'
            print(f'* Setting {name!r} to {value!r}')
            setattr(self, name, value)
            return value

data = ValidatingRecord()
print('exists: ', data.exists)
print('First foo: ', data.foo)
print('Second foo: ', data.foo)
>>>
* Called __getattribute__('exists')
* Found 'exists', returning 5
exists: 5
* Called __getattribute__('foo')
* Setting 'foo' to 'Value for foo'
First foo: Value for foo
* Called __getattribute__('foo')
* Found 'foo', returning 'Value for foo'
Second foo: Value for foo
```

Python code implementing generic functionality often relies on the `hasattr` built-in function to determine when properties exist, and the `getattr` built-in function to retrieve property values

The `__setattr__` method is always called every time an attribute is assigned on an instance (either directly or through the setattr built-in function)

The problem with `__getattribute__` and `__setattr__` is that they’re called on every attribute access for an object, even when you may not want that to happen

```python
class BrokenDictionaryRecord:
	def __init__(self, data):
		self._data = {}
	
	def __getattribute__(self, name):
		print(f'* Called __getattribute__({name!r})')
		return self._data[name]
```

This requires accessing `self._data` from the `__getattribute__`
method

```python
data = BrokenDictionaryRecord({'foo': 3})
data.foo
>>>
* Called __getattribute__('foo')
* Called __getattribute__('_data')
* Called __getattribute__('_data')
* Called __getattribute__('_data')
...
Traceback ...
RecursionError: maximum recursion depth exceeded while calling a Python object
```

The problem is that `__getattribute__` accesses `self._data`, which causes `__getattribute__` to run again

The solution is to use the `super().__getattribute__` method to fetch values from the instance attribute dictionary

```python
class DictionaryRecord:
	def __init__(self, data):
		self._data = data

	def __getattribute__(self, name):
		print(f'* Called __getattribute__({name!r})')
		data_dict = super().__getattribute__('_data')
		return data_dict[name]

data = DictionaryRecord({'foo': 3})
print('foo: ', data.foo)
>>>
* Called __getattribute__('foo')
foo: 3
```

`__setattr__` methods that modify attributes on an object also need to use `super().__setattr__` accordingly

- Use __getattr__ and __setattr__ to lazily load and save attributes for an object
- Understand that __getattr__ only gets called when accessing a missing attribute, whereas __getattribute__ gets called every time any attribute is accessed
- Avoid infinite recursion in __getattribute__ and __setattr__ by using methods from super() (i.e., the object class) to access instance attributes

## Item 48: Validate Subclasses with __init_subclass__

One of the simplest applications of metaclasses is verifying that a class was defined correctly

A metaclass is defined by inheriting from `type`

In the default case, a metaclass receives the contents of associated class statements in its `__new__` method

```python
class Meta(type):
    def __new__(meta, name, bases, class_dict):
        print(f'* Running {meta}.__new__ for {name}')
        print('Bases:', bases)
        print(class_dict)
        return type.__new__(meta, name, bases, class_dict)

class MyClass(metaclass=Meta):
    stuff = 123

    def foo(self):
        pass

class MySubclass(MyClass):
    other = 567

    def bar(self):
        pass
```

The metaclass has access to the name of the class, the parent classes it inherits from (bases), and all the class attributes that were defined in the class’s body

```
>>>
* Running <class '__main__.Meta'>.__new__ for MyClass
Bases: ()
{'__module__': '__main__',
'__qualname__': 'MyClass',
'stuff': 123,
'foo': <function MyClass.foo at 0x105a05280>}
* Running <class '__main__.Meta'>.__new__ for MySubclass
Bases: (<class '__main__.MyClass'>,)
{'__module__': '__main__',
'__qualname__': 'MySubclass',
'other': 567,
'bar': <function MySubclass.bar at 0x105a05310>}
```

I can add functionality to the `Meta.__new__` method in order to validate all of the parameters of an associated class before it’s defined

For example, I want to represent any type of multisided polygon. I can do this by defining a special validating metaclass and using it in the base class of my polygon class hierarchy. Note that it’s important not to apply the same validation to the base class

```python
class ValidatePolygon(type):
    def __new__(meta, name, bases, class_dict):
        # Only validate subclasses of the Polygon class
        if bases:
            if class_dict['sides'] < 3:
                raise ValueError('Polygons need 3+ sides')
            return type.__new__(meta, name, bases, class_dict)

class Polygon(metaclass=ValidatePolygon):
    sides = None  # Must be specified by subclasses

    @classmethod
    def interior_angles(cls):
        return (cls.sides - 2) * 180

class Triangle(Polygon):
    sides = 3

class Rectangle(Polygon):
    sides = 4

class Nonagon(Polygon):
    sides = 9
```

If I try to define a polygon with fewer than 3 sides, the validation will cause the class statement to fail immediately after the class statement body => the program will not even be able to start running when I define such a class

```python
print('Before class')

class Line(Polygon):
    print('Before sides')
    sides = 2
    print('After sides')

print('After class')

>>>
Before class
Before sides
After sides
Traceback ...
ValueError: Polygons need 3+ sides
```

Python 3.6 introduced simplified syntax—the `__init_subclass__` special class method—for achieving the same behavior while avoiding metaclasses entirely

```python
class BetterPolygon:
    sides = None  # Must be specified by subclasses
    def __init_subclass__(cls):
        super().__init_subclass__()
        if cls.sides < 3:
            raise ValueError('Polygons need 3+ sides')

    @classmethod
    def interior_angles(cls):
        return (cls.sides - 2) * 180


class Hexagon(BetterPolygon):
    sides = 6
```

The code is much shorter now, and the `ValidatePolygon` metaclass is
gone entirely

access the `sides` attribute directly on the `cls` instance in `__init_subclass__` instead of `class_dict['sides']`

```python
print('Before class')

class Point(BetterPolygon):
    sides = 1

print('After class')
>>>
Before class
Traceback ...
ValueError: Polygons need 3+ sides
```

Another problem with the standard Python metaclass machinery is that you can only specify a single metaclass per class definition

```python
class ValidateFilled(type):
    def __new__(meta, name, bases, class_dict):
        # Only validate subclasses of the Filled class
        if bases:
            if class_dict['color'] not in ('red', 'green'):
                raise ValueError('Fill color must be supported')
            return type.__new__(meta, name, bases, class_dict)


class Filled(metaclass=ValidateFilled):
    color = None  # Must be specified by subclasses
```

When I try to use the Polygon metaclass and Filled metaclass together, I get a cryptic error message

```python
class RedPentagon(Filled, Polygon):
    color = 'red'
    sides = 5
>>>
Traceback ...
TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases
```

It’s possible to fix this by creating a complex hierarchy of metaclass
type definitions to layer validation

```python
class ValidateFilledPolygon(ValidatePolygon):
    def __new__(meta, name, bases, class_dict):
        # Only validate non-root classes
        if not class_dict.get('is_root'):
            if class_dict['color'] not in ('red', 'green'):
                raise ValueError('Fill color must be supported')
            return super().__new__(meta, name, bases, class_dict)


class FilledPolygon(Polygon, metaclass=ValidateFilledPolygon):
    is_root = True
    color = None  # Must be specified by subclasses

# 验证颜色

class OrangePentagon(FilledPolygon):
    color = 'orange'
    sides = 5

>>>
Traceback ...
ValueError: Fill color must be supported

# 验证形状

class RedLine(FilledPolygon):
    color = 'red'
    sides = 2

>>>
Traceback ...
ValueError: Polygons need 3+ sides
```

The `__init_subclass__` can be defined by multiple levels of a class hierarchy as long as the `super` built-in function is used to call any parent or sibling `__init_subclass__` definitions

```python
class Filled:
    color = None # Must be specified by subclasses
    def __init_subclass__(cls):
        super().__init_subclass__()
        if cls.color not in ('red', 'green', 'blue'):
            raise ValueError('Fills need a valid color')

# 同时验证
print('Before class')

class BlueLine(Filled, Polygon):
    color = 'blue'
    sides = 2

print('After class')

>>>
Before class
Traceback ...
ValueError: Polygons need 3+ sides
```

```python
class Top:
    def __init_subclass__(cls):
        super().__init_subclass__()
        print(f'Top for {cls}')

class Left(Top):
    def __init_subclass__(cls):
        super().__init_subclass__()
        print(f'Left for {cls}')

class Right(Top):
    def __init_subclass__(cls):
        super().__init_subclass__()
        print(f'Right for {cls}')

class Bottom(Left, Right):
    def __init_subclass__(cls):
        super().__init_subclass__()
        print(f'Bottom for {cls}')

>>>
Top for <class '__main__.Left'>
Top for <class '__main__.Right'>
Top for <class '__main__.Bottom'>
Right for <class '__main__.Bottom'>
Left for <class '__main__.Bottom'>
```

As expected, `Top.__init_subclass__` is called only a single time for each class, even though there are two paths to it for the Bottom class through its Left and Right parent classes

- The `__new__` method of metaclasses is run after the class statement’s entire body has been processed
- Metaclasses can be used to inspect or modify a class after it’s defined but before it’s created, but they’re often more heavyweight than what you need
- Use `__init_subclass__` to ensure that subclasses are well formed at the time they are defined, before objects of their type are constructed
- Be sure to call `super().__init_subclass__` from within your class’s `__init_subclass__` definition to enable validation in multiple layers of classes and multiple inheritance

## Item 49: Register Class Existence with `__init_subclass__`

Another common use of metaclasses is to automatically register types in a program

- Class registration is a helpful pattern for building modular Python programs
- Metaclasses let you run registration code automatically each time a base class is subclassed in a program
- Using metaclasses for class registration helps you avoid errors by ensuring that you never miss a registration call
- Prefer `__init_subclass__` over standard metaclass machinery because it’s clearer and easier for beginners to understand

## Item 50: Annotate Class Attributes with `__set_name__`

